---
title: "Stat 437 Final Project"
subtitle: "Stroke Prediction Data Analysis"
author: "Payton Bokowy, Freeman Chen, and Kane Anderson"
date: "4/30/2021"
output: pdf_document
---

\section{Abstract}
The World Health Organization (WHO) states that strokes are the second leading cause to death in the world. The data set looks at over 5,000 patients' health information and if the patient has had a stroke. We analyzed the patients' health data in order to predict if they were going to have a stroke. We used a logistic regression classifier, a non-linear support vector machine classifier, linear discriminant analysis, and K-nearest neighbor algorithm to predict the stroke status of the patient. 

\section{Introduction}
Since stroke is the second leading cause of death in the world, it would be beneficial to understand what factors may increase an individual's risk at having a stroke. This data set looks at individuals' health data such as their BMI, blood pressure, gender, and if they have been diagnosed with heart disease. It also looks at certain events in the individual's life such as, if they have ever been married, if they have ever smoked, and what kind of work they do and where they live. Given this data, we tried to classify the patients into a stroke and non-stroke group. We attempted to do this by using a variety of different classification methods. 

\section{Methods}
We decided to use different types of classifications to help predict whether a patient was going to have a stroke. We analyzed the data with a logistic regression, non-linear support vector machine, linear discriminant analysis, and K-nearest neighbor algorithm to do so. Before starting any of the classifications, the data needed to be cleaned up. We took out the values containing NA and changed many of the variables to factors. We also took out the ID number. We then split the data into two groups: one for training the models and another for testing the models. 

```{r, message=F, warning=F, echo=F}
library(ggplot2)
library(e1071)
library(lmtest)
library(MASS)
library(class)
library(pheatmap)
```

```{r, warning=F}
data = read.csv("healthcare-dataset-stroke-data.csv") # reads data file
data = subset(data, select = -c(id)) # gets rid of the id

# changes the predictors to factors
data$gender = as.factor(data$gender)
data$hypertension = as.factor(data$hypertension)
data$heart_disease = as.factor(data$heart_disease)
data$ever_married = as.factor(data$ever_married)
data$work_type = as.factor(data$work_type)
data$Residence_type = as.factor(data$Residence_type)
data$smoking_status = as.factor(data$smoking_status)
data$stroke = as.factor(data$stroke)
data$bmi = as.numeric(data$bmi)
prop.table(table(data$stroke))
data = na.omit(data)

# splits the data into a testing and training set
set.seed(1)
n = dim(data)[1]
train = seq(from = 1, to = n, by = 2)
training = data[train, ]
testing = data[-train, ]

training = as.data.frame(training)
testing = as.data.frame(testing)
```
As we see the minority class number “1” is only about 4.25% of the total cases. As we can see from the output, most observations are a 1, which means the data is highly unbalanced. This will result in the accuracy score to be nearly 1, but the model performance will be very poor. The only model affected by this will be the logistic model. We ran the logistic model without any synthetic data first, and then ran it after. This will improve the performance of the logistic regression model. The SVM, LDA, and KNN models don't need synthetic data because the models are not classifiers. 


## Data Exploration
We looked into the relationships between predictors before we applied the methods to predict if a person is likely to have a stroke based on their history and health data. 

```{r BMI data exploration, warning=F, message=F, fig.height=3, fig.width=5}
summary(data)

# graph the distribution of BMI
ggplot(data, aes(x = data$bmi)) +
geom_histogram() + labs(title = "Distribution of BMI") +
  ylab(label = "Count") +
  xlab(label = "BMI") 
```

From the distribution graph we can see the most of the BMI value are around 20 to 30 years old.

```{r BMI and Age exploration, fig.height=3, fig.width=5}
ggplot()+ geom_point(mapping = aes(x = data$age, y=data$bmi))+
  ggtitle(label = "Age vs. BMI")+
  ylab(label = "BMI")+
  xlab(label = "Age")
```

From the graph we can see that the age group around 40-55 years have the highest BMI.

```{r Work Type data exploration, fig.height=3, fig.width=5}
stroke_data = data[which(data$stroke == "1"), ]

ggplot(stroke_data, aes(x=stroke_data$work_type, y=stroke_data$stroke, 
                        fill = stroke_data$age))+
  geom_bar(stat='identity')+
  ylab(label = "Stroke")+
  xlab(label = "Work Type")
``` 

Given that the person had a stroke, the private sector has almost double the number of strokes than any other work type.

## Logistic Regression Classification

The first approach we took was using a logistic regression classification to help classify each patient into a stroke and non-stroke group. With this classification, we can use it to predict if a patient will have a stroke given their personal health information. 

```{r logistic regression, fig.height=4, fig.width=6}
# performs logistic regression on the stroke data
full_logistic = glm(stroke~., data = training, family = "binomial")
summary(full_logistic)

# predicts on the testing data
probs = predict(full_logistic, type = "response", testing) 

n = dim(testing)[1]
t = 0.5
pred.label = c()
pred.label = rep(1, n)
pred.label[probs>t] = 0

table(predicted = pred.label, truth = testing$stroke) # confusion matrix
log_error = (2345 + 4)/n
log_error

# plots the ROC Curve
tseq = seq(0.001, 0.999, length.out = 100)
sensitivity = c(); specificity = c()

for (j in 1:length(tseq)){
t = tseq[j]

pred.label[probs>t] = 1
pred.label[probs < t] = 0

p.ind = which(testing$stroke == 1)
sensitivity[j] = mean(pred.label[p.ind] == testing$stroke[p.ind])

n.ind = which(testing$stroke == 0)  
specificity[j] = mean(pred.label[n.ind] == testing$stroke[n.ind])
}

plot(1 - specificity, sensitivity, type = "l", xlim = c(0, 1), ylim = c(0, 1))
abline(a = 0, b = 1)
```

Based on the error rate for the logistic regression, it is not an accurate model to determine is a patient is likely to have a stroke. The logistic regression model has a 95.72% error rate. This error rate is extremely high, so we did cross validation on the data set to improve our model.

## Logistic Regression Classifier with Cross Validation
```{r, warning=F, message=F, fig.height=4, fig.width=6}
library(ROSE)
set.seed(1)

trainrose<-ROSE(stroke~.,data=training)$data
table(trainrose$stroke)

full_logistic = glm(stroke~., data = trainrose, family = "binomial")

probs <- predict(full_logistic, type = "response", testing)
n = dim(testing)[1]
t = 0.5
pred.label = c()
pred.label = rep(0, n)
pred.label[probs>t] = 1
table(predicted = pred.label, truth = testing$stroke)

new_log_error = (550 + 28) /n
new_log_error

# plots the ROC Curve
tseq = seq(0.001, 0.999, length.out = 100)
sensitivity = c(); specificity = c()

for (j in 1:length(tseq)){
t = tseq[j]

pred.label[probs>t] = 1
pred.label[probs < t] = 0

p.ind = which(testing$stroke == 1)
sensitivity[j] = mean(pred.label[p.ind] == testing$stroke[p.ind])

n.ind = which(testing$stroke == 0)  
specificity[j] = mean(pred.label[n.ind] == testing$stroke[n.ind])
}

plot(1 - specificity, sensitivity, type = "l", xlim = c(0, 1), ylim = c(0, 1))
abline(a = 0, b = 1)
```
The first logistic regression model has most predictions on one side. Once we saw this outcome, we used ROSE package to balance the data set. This technique added new synthetic data points to the minority class and down samples the majority class. It improves the performance of the logistic regression model. The updated error rate is 23.55% which is much better than the previous error rate of 95.72%.  

## Radial Support Vector Machine

We then used a non-linear support vector machine. We chose to use the radial kernel method for the support vector machine. The svm helps predict if a patient has had a stroke. 
```{r svm}
# performs radial support vector machine 
#svm.rad = tune(svm, stroke~., data = training, kernel = "radial", 
# ranges = list(cost = c(0.1, 1, 10, 100, 1000),degree = c(1,2,3,4,5), 
# gamma = c(0.01,0.1,1,10)))

#svm.best = svm.rad$best.model

###best model: cost = 1000, gamma = 0.01, degree = 1 
svm.best = svm(stroke~., data = training, kernel = "radial", 
               cost = 1000, gamma = 0.01, degree =1)

# predicts on the testing set
svm.pred = predict(svm.best, testing)
table(predicted = svm.pred, truth = testing$stroke) # confusion matrix
summary(svm.best)
plot(svm.best, data=data[-train, ])
svm_error = (2+104) / n
svm_error
```

The non-linear support vector machine model is a good predictor if a patient will have a stroke based on their history and health data. There is only a 4.3% error rate for the non-linear svm model. 

## Linear Discriminant Analysis
Next, we used linear discriminant analysis to try to classify the patients into the correct stroke and non-stroke groups. 
```{r lda}
lda.fit = lda(stroke~., data = training) # performs LDA classification

lda.pred = predict(lda.fit, testing)  # predicts on the test set

table(prediction = lda.pred$class, truth = testing$stroke)  # confusion matrix

lda_error = (51 + 90) / n
lda_error
```

The linear discriminant analysis is also a good model to predict if a patient will have a stroke. There is only a 5.7% error rate with the model.

## K-Nearest Neighbors
```{r}
set.seed(1)
train.x = training[,c(2,8,9)]
test.x = testing[,c(2,8,9)]
train.stroke = training[,11]

knn.fit = knn(train.x, test.x, train.stroke, k = 1)

table(prediction = knn.fit, truth = testing$stroke)

k_error = (89 + 77) / 2454
k_error

tpms = c()

for(k in 1:15){
  knn.fit = knn(train.x, test.x, train.stroke, k = k)
  confTab <- table(prediction = knn.fit, truth = testing$stroke)
  tpms[k] = (confTab[1, 2] + confTab[2, 1]) / 2454
}
min(tpms) #0.0424
which.min(tpms) #K=15
```

The KNN was able to return an error rate of around 4.24% with K = 15 clusters to arrive at that value, however we were forced to use KNN with only our 3 numeric variables, as KNN cannot use factors of more than 2 levels after some research on Kane's end.

\section{Results}
After carrying out the logistic regression, non-linear support vector machine, linear discriminant analysis, and K-nearest neighbors, we calculated the error rate to determine which model best predicts if someone is likely to have a stroke. The logistic regression with synthetic data had the highest error rate between all the models we created. The model had a 23.55%. The next model we implemented was the non-linear support vector machine. Using a radial kernel with degree = 1 and cost = 1000 and gamma = 0.01. This model was significantly better at predicting the stroke status of a person. The error rate of the support vector machine was only 4.3%. This was one of the better models we implemented to predict the status of a person having a stroke. Linear Discriminant Analysis had a similar error rate. The linear discriminant analysis only had a 5.7% error which is also very low, but the non-linear support vector machine is better. Finally, we attempted K-nearest neighbors algorithm on the data. This method gave us the lowest error rate, and thus, the best model at predicting a person's stroke status. The error rate for the K-nearest neighbor was only 4.24% which is very close to the non-linear support vector machine error of 4.3%. 

We analyzed the results of each method, and the K-nearest neighbors was the best predictor. It only used three predictors, and it still had the lowest error rate. The non-linear support vector machine was a near second best model. However, the non-linear svm model used all predictors while K-nearest neighbor was able to have a lower error rate with far fewer predictors. 

Since K-nearest neighbors only used the age, BMI, and glucose levels to predict if the person would have a stroke, those three predictors are the biggest indicators of whether a person is likely to have a stroke. 

\section{Discussion}
In this case of study, the K-nearest neighbor model has the best performance compared to the other models we tested. This model only used our numerical variables which were age, average glucose levels, and BMI. This could be a result of why our KNN model was the best predictor. For further investigation, we could run all the other models on only those three predictors. Furthermore, that could be a reason of using the highly unbalanced data, in a real-world data set, mostly majority class bias exists, and required training data could be very less. When we train our model with such unbalanced data, the accuracy score would be nearly 1 but model performance will be very poor. This could be an issue with the methods we tested. Going forward, we may want to collect more data that is balanced in terms of observations resulting in a stroke or no stroke.

\section{Group Contributions}
Payton Bokowy wrote up the abstract, introduction, and the methods section. Payton also did the logistic regression and the linear discriminant analysis. 

Freeman Chen did the non-linear svm model and created all the graphs for us to analyze. Freeman also wrote up the discussion section of the project and performed the logistic regression with cross validation. 

Kane Anderson cleaned the data, so we didn't use the ID number in any of our analyses. Kane also did the K-nearest neighbor method and researched how we could include the KNN method with our data.

